{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [],
         "source": [
            "import requests\n",
            "from bs4 import BeautifulSoup\n",
            "import re\n",
            "import json\n",
            "import pandas as pd\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            "\n",
            "def scrape_vehicle_data(url):\n",
            "    # Send a GET request to the URL\n",
            "    response = requests.get(url)\n",
            "\n",
            "    # Parse the HTML content using BeautifulSoup\n",
            "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
            "\n",
            "    # Find all <script> tags with type \"application/ld+json\"\n",
            "    json_scripts = soup.find_all(\"script\", type=\"application/ld+json\")\n",
            "\n",
            "    # Define an empty list to store extracted vehicle information\n",
            "    vehicles = []\n",
            "\n",
            "    # Define a set to store seen vehicle names\n",
            "    seen_vehicles = set()\n",
            "\n",
            "    # Loop through each <script> tag\n",
            "    for script in json_scripts:\n",
            "        # Extract the text content of the <script> tag\n",
            "        if json_text := script.string:\n",
            "            # Remove special characters from the JSON text\n",
            "            json_text_cleaned = re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', '', json_text)\n",
            "\n",
            "            # Parse the JSON data into a Python dictionary\n",
            "            json_data = json.loads(json_text_cleaned)\n",
            "\n",
            "            # Check if the JSON data represents a list of vehicles (ItemList)\n",
            "            if \"@type\" in json_data and json_data[\"@type\"] == \"ItemList\":\n",
            "                # Get the list of vehicles\n",
            "                vehicle_list = json_data[\"itemListElement\"]\n",
            "\n",
            "                # Iterate over each vehicle entry\n",
            "                for vehicle_item in vehicle_list:\n",
            "                    # Extract vehicle information\n",
            "                    vehicle_info = vehicle_item[\"item\"]\n",
            "\n",
            "                    # Extract the vehicle name\n",
            "                    vehicle_name = vehicle_info[\"name\"]\n",
            "\n",
            "                    # If the vehicle name is not already seen, add it to the list and mark it as seen\n",
            "                    if vehicle_name not in seen_vehicles:\n",
            "                        vehicles.append(vehicle_info)\n",
            "                        seen_vehicles.add(vehicle_name)\n",
            "\n",
            "    # Create a DataFrame from the list of vehicle dictionaries\n",
            "    df = pd.DataFrame(vehicles)\n",
            "\n",
            "    # Extract 'name' and 'price' from the 'offers' section, then drop the 'offers' column and rename the 'name' column\n",
            "    df['price'] = df['offers'].apply(lambda x: x['price'])\n",
            "    df.drop(columns=['offers'], inplace=True)\n",
            "    df.rename(columns={'name': 'Vehicle Name'}, inplace=True)\n",
            "\n",
            "    df = df[['Vehicle Name', 'price']]\n",
            "\n",
            "\n",
            "    # Adjust DataFrame index to start from 1\n",
            "    df.index += 1\n",
            "\n",
            "    # Convert 'price' column to floating-point numbers\n",
            "    df['price'] = df['price'].astype(float)\n",
            "\n",
            "    # Convert 'price' column to integers\n",
            "    df['price'] = df['price'].astype(int)\n",
            "\n",
            "    return df"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Define the list of URLs to scrape\n",
            "urls = [\n",
            "    \"https://www.acadiatoyota.com/en/new-inventory\",\n",
            "   \n",
            "    \"https://www.charlottetowntoyota.ca/en/new-catalog\",\n",
            "   \n",
            "    \"https://www.westerntoyota.com/en/new-catalog\",\n",
            "    \"https://www.grandtoyota.ca/en/new-catalog\",\n",
            "   \n",
            "    \"https://www.rousseltoyota.com/en/new-inventory\",\n",
            "\n",
            "]\n",
            "\n",
            "# Create an empty list to store DataFrames\n",
            "dfs = []\n",
            "\n",
            "# Create an empty list to store URLs that couldn't be scraped\n",
            "failed_urls = []\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Successfully scraped data from https://www.acadiatoyota.com/en/new-inventory\n",
                  "Successfully scraped data from https://www.charlottetowntoyota.ca/en/new-catalog\n",
                  "Successfully scraped data from https://www.westerntoyota.com/en/new-catalog\n",
                  "Successfully scraped data from https://www.grandtoyota.ca/en/new-catalog\n",
                  "Successfully scraped data from https://www.rousseltoyota.com/en/new-inventory\n"
               ]
            }
         ],
         "source": [
            "# Iterate over each URL and scrape vehicle data\n",
            "for url in urls:\n",
            "    try:\n",
            "        df = scrape_vehicle_data(url)  # Assuming scrape_vehicle_data function is defined as mentioned earlier\n",
            "        df['Source Website'] = url  # Add a column for the source website\n",
            "        dfs.append(df)\n",
            "        print(f\"Successfully scraped data from {url}\")\n",
            "    except Exception as e:\n",
            "        print(f\"Failed to scrape data from {url}: {e}\")\n",
            "        failed_urls.append(url)\n",
            "\n",
            "# Concatenate all DataFrames into a single DataFrame\n",
            "final_df = pd.concat(dfs, ignore_index=True)\n",
            "\n",
            "# # Create a DataFrame for failed URLs\n",
            "# failed_df = pd.DataFrame({'Failed URLs': failed_urls})\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [],
         "source": [
            "final_df.to_csv('./data_part_1.csv',)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "p39 no one",
         "language": "python",
         "name": "p39"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.11"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
