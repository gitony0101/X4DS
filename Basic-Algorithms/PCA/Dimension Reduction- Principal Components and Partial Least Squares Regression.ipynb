{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Dimension Reduction: Principal Components and Partial Least Squares Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Objectives:\n",
    "\n",
    "    Explain how principal components regression and partial squares regression work.\n",
    "\n",
    "    Show Python code to to perform Principal Components Regression and Partial Least Squares Regression\n",
    "\n",
    "Overview:\n",
    "\n",
    "Principal Components Regression (PCR) and Partial Least Squares Regression (PLS) are yet two other alternatives to simple linear model fitting that often produces a model with better fit and higher accuracy.  Both are dimension reduction methods but PCR offers an unsupervised approach, while PCL is a supervised alternative.\n",
    "\n",
    "Principal Components Regression: \n",
    "\n",
    "The approach is based on reducing the number of predictors into a smaller dimension using principal components analysis.  These principal components then are used as regressors when fitting a new OLS model.  \n",
    "\n",
    "Since a relatively small number of principal components explain a large percent of the variability in data, the approach may be sufficient in explaining a relationship between the target variable and the principal components that were constructed from a larger number of regressor variables. \n",
    "\n",
    "One drawback of PCR, is that it is based on an unsupervised approach to feature reduction: Principal Components Analysis.  PCA is set out to find linear combinations that best describe original regressors. Since detection of these linear combinations was performed without using a target variable, we canâ€™t be certain that the principal components we created are the best to use to predict the target variable.  It is entirely possible, that a different set of principal components would perform better. The solution to this problem is Partial Least Squares Regression (more about that later).\n",
    "\n",
    "Still, the PCA approach is a good way to overcome multicollinearity problems in OLS models.  Further, since PCA is a dimension reduction approach, PCR may be a good way of attacking problems with high-dimensional covariates.  \n",
    "\n",
    " PCR follows three steps: \n",
    "\n",
    "1.     Find principal components from the data matrix of original regressors. \n",
    "\n",
    "2.     Regress the outcome variable on the selected principal components, which are covariates of the original regressors.  The regression used should be OLS. \n",
    "\n",
    "3.     Transform the findings back to the scale of the covariates using PCA loadings to get a PCR estimator so that regression coefficients can be estimated.    \n",
    "\n",
    " PCR vs. Shrinkage:\n",
    "\n",
    "Sometimes, PCR can outperform shrinkage models (in terms of model error), while other times shrinkage models are better.  If relatively few principal components are needed to explain variance in the data, then PCR will outperform shrinkage methods such as ridge, lasso or elastic net models.  If more principal components are required, then shrinkage methods will perform better.  \n",
    "\n",
    "Principal Components Regression and the Boston Housing Data:\n",
    "\n",
    "First, we need load all required libraries, most of them as part of the sklearn package"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn import model_selection\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.cross_decomposition import PLSRegression, PLSSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   MEDV\n",
       "0  25.0\n",
       "1  22.6\n",
       "2  35.7\n",
       "3  34.4\n",
       "4  37.2"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MEDV</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>35.7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>34.4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>37.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#load and partition data\n",
    "from sklearn.datasets import load_boston\n",
    "boston= load_boston()\n",
    "\n",
    "boston_features_df = pd.DataFrame(data=boston.data,columns=boston.feature_names)\n",
    "boston_target_df = pd.DataFrame(data=boston.target,columns=['MEDV'])\n",
    "\n",
    "#Transform data \n",
    "#add one to each value to get rid of 0 values in both target and features\n",
    "\n",
    "numeric_cols = [col for col in boston_features_df if boston_features_df[col].dtype.kind != 'O']\n",
    "numeric_cols\n",
    "numeric_cols2 = [col for col in boston_target_df if boston_target_df[col].dtype.kind != 'O']\n",
    "numeric_cols2\n",
    "\n",
    "boston_features_df[numeric_cols] += 1\n",
    "boston_target_df[numeric_cols2] += 1\n",
    "boston_features_df.head()\n",
    "boston_target_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'ColumnTransformer' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4702f313ea62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Box-Cox Transform features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m column_trans = ColumnTransformer(\n\u001b[0m\u001b[1;32m      3\u001b[0m     [('CRIM_bc', PowerTransformer(method='box-cox', standardize=True), ['CRIM']),\n\u001b[1;32m      4\u001b[0m      \u001b[0;34m(\u001b[0m\u001b[0;34m'ZN_bc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPowerTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'box-cox'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ZN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m      \u001b[0;34m(\u001b[0m\u001b[0;34m'INDUS_bc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPowerTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'box-cox'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'INDUS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ColumnTransformer' is not defined"
     ]
    }
   ],
   "source": [
    "#Box-Cox Transform features\n",
    "column_trans = ColumnTransformer(\n",
    "    [('CRIM_bc', PowerTransformer(method='box-cox', standardize=True), ['CRIM']),\n",
    "     ('ZN_bc', PowerTransformer(method='box-cox', standardize=True), ['ZN']),\n",
    "     ('INDUS_bc', PowerTransformer(method='box-cox', standardize=True), ['INDUS']),\n",
    "     ('CHAS_bc', PowerTransformer(method='box-cox', standardize=True), ['CHAS']),\n",
    "     ('NOX_bc', PowerTransformer(method='box-cox', standardize=True), ['NOX']),\n",
    "     ('RM_bc', PowerTransformer(method='box-cox', standardize=True), ['RM']),\n",
    "     ('AGE_bc', PowerTransformer(method='box-cox', standardize=True), ['AGE']),\n",
    "     ('DIS_bc', PowerTransformer(method='box-cox', standardize=True), ['DIS']),\n",
    "     ('RAD_bc', PowerTransformer(method='box-cox', standardize=True), ['RAD']),\n",
    "     ('TAX_bc', PowerTransformer(method='box-cox', standardize=True), ['TAX']),\n",
    "     ('PTRATIO_bc', PowerTransformer(method='box-cox', standardize=True), ['PTRATIO']),\n",
    "     ('B_bc', PowerTransformer(method='box-cox', standardize=True), ['B']),\n",
    "     ('LSTAT_bc', PowerTransformer(method='box-cox', standardize=True), ['LSTAT']),\n",
    "    ])\n",
    "\n",
    "transformed_boxcox = column_trans.fit_transform(boston_features_df)\n",
    "new_cols = ['CRIM_bc', 'ZN_bc', 'INDUS_bc', 'CHAS_bc', 'NOX_bc', 'RM_bc', 'AGE_bc', 'DIS_bc','RAD_bc','TAX_bc','PTRATIO_bc', 'B_bc', 'LSTAT_bc']\n",
    "\n",
    "boston_features_bc = pd.DataFrame(transformed_boxcox, columns=new_cols)\n",
    "pd.concat([ boston_features_bc], axis = 1)\n",
    "boston_features_bc.head()\n",
    "##### Box-Cox tranform target\n",
    "column_trans = ColumnTransformer(\n",
    "    [('MEDV_bc', PowerTransformer(method='box-cox', standardize=True), ['MEDV']),\n",
    "    ])\n",
    "    \n",
    "transformed_boxcox = column_trans.fit_transform(boston_target_df)\n",
    "new_cols2 = ['MEDV_bc']\n",
    "\n",
    "boston_target_bc = pd.DataFrame(transformed_boxcox, columns=new_cols2)\n",
    "pd.concat([ boston_target_bc], axis = 1)\n",
    "boston_target_bc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}