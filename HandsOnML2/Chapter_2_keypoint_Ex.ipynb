{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Chapter 2 keypoint EX"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "With increasing demand in machine learning and data science in businesses, for **upgraded data strategizing** there’s a need for a **better workflow** to **ensure robustness in data modelling**. \n",
    "\n",
    "Machine learning has certain steps to be followed namely – data collection, data preprocessing(cleaning and feature engineering), model training, validation and prediction on the test data(which is previously unseen by model). \n",
    "\n",
    "Here testing data needs to go through the same preprocessing as training data.**For this iterative process**, **pipelines** are used which can automate the entire process for both training and testing data. It ensures reusability of the model by reducing the redundant part, thereby speeding up the process. This could prove to be very effective during the production workflow.\n",
    "\n",
    "**Advantages of using Pipeline:**\n",
    "\n",
    "- Automating the workflow being iterative.\n",
    "- Easier to fix bugs \n",
    "- Production Ready\n",
    "- Clean code writing standards\n",
    "- Helpful in iterative hyperparameter tuning and cross-validation evaluation\n",
    "\n",
    "**Challenges in using Pipeline:**\n",
    "\n",
    "- Proper data cleaning\n",
    "- Data Exploration and Analysis\n",
    "- Efficient feature engineering\n",
    "\n",
    "**Scikit-Learn Pipeline**\n",
    "\n",
    "The sklearn.pipeline module implements utilities to build a composite estimator, as a chain of transforms and estimators.\n",
    "\n",
    "With the **scikit learn pipeline**, we can easily systemise the process and therefore make it extremely reproducible.\n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pipeline 1 : [Daily bike share]((https://towardsdatascience.com/step-by-step-tutorial-of-sci-kit-learn-pipeline-62402d5629b6))"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data = pd.read_csv('../data/daily-bike-share.csv')\n",
    "data.dtypes"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "instant         int64\n",
       "dteday         object\n",
       "season          int64\n",
       "yr              int64\n",
       "mnth            int64\n",
       "holiday         int64\n",
       "weekday         int64\n",
       "workingday      int64\n",
       "weathersit      int64\n",
       "temp          float64\n",
       "atemp         float64\n",
       "hum           float64\n",
       "windspeed     float64\n",
       "rentals         int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "data.isnull().sum() # clear"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "instant       0\n",
       "dteday        0\n",
       "season        0\n",
       "yr            0\n",
       "mnth          0\n",
       "holiday       0\n",
       "weekday       0\n",
       "workingday    0\n",
       "weathersit    0\n",
       "temp          0\n",
       "atemp         0\n",
       "hum           0\n",
       "windspeed     0\n",
       "rentals       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# label\n",
    "data = data[['season'\n",
    "             , 'mnth'\n",
    "             , 'holiday'\n",
    "             , 'weekday'\n",
    "             , 'workingday'\n",
    "             , 'weathersit'\n",
    "             , 'temp'\n",
    "             , 'atemp'\n",
    "             , 'hum'\n",
    "             , 'windspeed'\n",
    "             , 'rentals']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = data.drop('rentals', axis=1)\n",
    "y = data['rentals']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=123)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create the pipeline\n",
    "\n",
    "The main parameter of a pipeline we’ll be working on is ‘steps’.\n",
    "\n",
    " From the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#examples-using-sklearn-pipeline-pipeline),it is a *‘list of (name, transform) tuples (implementing fit/transform) that are chained, in the order in which they are chained, with the last object an estimator.'*\n",
    "\n",
    "It’s easier to just have a glance at what the pipeline should look like:\n",
    "\n",
    "        Pipeline(steps=[('name_of_preprocessor', preprocessor),\n",
    "                        ('name_of_ml_model', ml_model())])"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant')), \n",
    "    ('encoder',OrdinalEncoder())\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "####  Apply ColumnTransformer\n",
    "\n",
    "Specify which columns are numeric and which are categorical, so we can apply the transformers accordingly.\n",
    "\n",
    " We apply the transformers to features by using `ColumnTransformer`. \n",
    " \n",
    " Applying the transformers to features is our preprocessor. \n",
    " \n",
    " Similar to pipeline, we pass **a list of tuples**, which is composed of *(‘name’, ‘transformer’, ‘features’)*, to the parameter **‘transformers’.**\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "numeric_features =['temp', 'atemp', 'hum', 'windspeed']\n",
    "\n",
    "categorical_features = ['season', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit']\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('numeric',numeric_transformer, numeric_features),  ## Specify, or \"map\" the num pipeline with the num features\n",
    "    ('categorical',categorical_transformer, categorical_features)  ## Specify, or \"map\" the cat pipeline with the cat features\n",
    "])\n",
    "## Not preferred:\n",
    "# numeric_features = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "# categorical_features = data.select_dtypes(include=['object']).drop(['Loan_Status'], axis=1).columns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Estimator with Random Forest Regression model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "pipeline = Pipeline(steps =[\n",
    "    ('preprocessor', preprocessor), # preprocessor from the ColumnTransformer\n",
    "    ('regressor', RandomForestRegressor())\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we make antoher **pipeline** with previos preprocessor,which made of two **pipelines**:\n",
    "\n",
    "`numeric_transformer & category_transformer`,meanwhile they all come from basic pipelines.\n",
    "\n",
    "Also, RandomForestRegressor added up in the new pipeline."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Train the model:\n",
    "rf_model = pipeline.fit(X_train,y_train)\n",
    "print(rf_model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('numeric',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer()),\n",
      "                                                                  ('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  ['temp', 'atemp', 'hum',\n",
      "                                                   'windspeed']),\n",
      "                                                 ('categorical',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='constant')),\n",
      "                                                                  ('encoder',\n",
      "                                                                   OrdinalEncoder())]),\n",
      "                                                  ['season', 'mnth', 'holiday',\n",
      "                                                   'weekday', 'workingday',\n",
      "                                                   'weathersit'])])),\n",
      "                ('regressor', RandomForestRegressor())])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Amazing and beautiful, isn't it?\n",
    "\n",
    "It makes clear of pipeline working process."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from sklearn.metrics import r2_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "predictions = rf_model.predict(X_test)\n",
    "r2_pred = r2_score(y_test,predictions)\n",
    "print(r2_pred)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.7645969743001761\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Use the model\n",
    "\n",
    "To maximise reproducibility, we‘d like to use this model repeatedly for our new incoming data. Let’s save the model by using ‘joblib’ package to save it as a pickle file."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "import joblib"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "joblib.dump(rf_model,'./rf_model.pkl')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['./rf_model.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can call this pipeline, which includes all sorts of data preprocessing we need and the training model, whenever we need it：\n",
    "\n",
    "        # In other notebooks \n",
    "        rf_model = joblib.load('PATH/TO/rf_model.pkl')\n",
    "        \n",
    "        new_prediction = rf_model.predict(new_data)\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conclusion\n",
    "\n",
    "Scikit learn pipeline makes workflows smoother and more flexible. \n",
    "\n",
    "For example, you can easily compare the performance of a number of algorithms like:\n",
    "\n",
    "        regressors = [\n",
    "            regressor_1()\n",
    "           ,regressor_2()\n",
    "           ,regressor_3()\n",
    "           ....]for regressor in regressors:\n",
    "            pipeline = Pipeline(steps = [\n",
    "                       ('preprocessor', preprocessor)\n",
    "                      ,('regressor',regressor)\n",
    "                   ])\n",
    "            model = pipeline.fit(X_train, y_train)\n",
    "            predictions = model.predict(X_test)\n",
    "            print (regressor)\n",
    "            print (f('Model r2 score:{r2_score(predictions, y_test)}')"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "or adjust the preprocessing/transforming methods. For instance, use ‘median’ value to fill missing values, use a different scaler for numeric features, change to one-hot encoding instead of ordinal encoding to handle categorical features, hyperparameter tuning, etc.\n",
    "\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "               ('imputer', SimpleImputer(strategy='median'))\n",
    "              ,('scaler', MinMaxScaler())\n",
    "        ])categorical_transformer = Pipeline(steps=[\n",
    "               ('imputer', SimpleImputer(strategy='constant'))\n",
    "              ,('encoder', OneHotEncoder())\n",
    "        ])pipeline = Pipeline(steps = [\n",
    "                       ('preprocessor', preprocessor)\n",
    "                      ,('regressor',RandomForestRegressor(n_estimators=300\n",
    "                                                         ,max_depth=10))\n",
    "                   ])"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pipeline 2: [Iris dataset](https://analyticsindiamag.com/hands-on-tutorial-on-machine-learning-pipelines-with-scikit-learn/) "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "iris_df = load_iris()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "titanic = pd.read_csv('../data/titanic.csv')\n",
    "titanic.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "titanic.info"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of      survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
       "0           0       3    male  22.0      1      0   7.2500        S   Third   \n",
       "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
       "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
       "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
       "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
       "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
       "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
       "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
       "888         0       3  female   NaN      1      2  23.4500        S   Third   \n",
       "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
       "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
       "\n",
       "       who  adult_male deck  embark_town alive  alone  \n",
       "0      man        True  NaN  Southampton    no  False  \n",
       "1    woman       False    C    Cherbourg   yes  False  \n",
       "2    woman       False  NaN  Southampton   yes   True  \n",
       "3    woman       False    C  Southampton   yes  False  \n",
       "4      man        True  NaN  Southampton    no   True  \n",
       "..     ...         ...  ...          ...   ...    ...  \n",
       "886    man        True  NaN  Southampton    no   True  \n",
       "887  woman       False    B  Southampton   yes   True  \n",
       "888  woman       False  NaN  Southampton    no  False  \n",
       "889    man        True    C    Cherbourg   yes   True  \n",
       "890    man        True  NaN   Queenstown    no   True  \n",
       "\n",
       "[891 rows x 15 columns]>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "X = titanic[['pclass', 'age', 'sex']]\n",
    "y = titanic['survived']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "X['age'].fillna(X['age'].mean(), inplace= True)\n",
    "# X.info"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/p39/lib/python3.9/site-packages/pandas/core/generic.py:6392: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25, random_state=42)\n",
    "X"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     pclass        age     sex\n",
       "0         3  22.000000    male\n",
       "1         1  38.000000  female\n",
       "2         3  26.000000  female\n",
       "3         1  35.000000  female\n",
       "4         3  35.000000    male\n",
       "..      ...        ...     ...\n",
       "886       2  27.000000    male\n",
       "887       1  19.000000  female\n",
       "888       3  29.699118  female\n",
       "889       1  26.000000    male\n",
       "890       3  32.000000    male\n",
       "\n",
       "[891 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=33)\n",
    "X_train = X_train.to_dict(orient='record')\n",
    "X_test = X_test.to_dict(orient='record')\n",
    "#将非数值型数据转换为数值型数据\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "clf = Pipeline([('vecd',DictVectorizer(sparse=False)),('dtc',DecisionTreeClassifier())])\n",
    "vec = DictVectorizer(sparse=False)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print (clf.score(X_test,y_test))\n",
    "print(classification_report(y_predict,y_test,target_names=['died','survivied']))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8340807174887892\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        died       0.90      0.84      0.87       143\n",
      "   survivied       0.74      0.82      0.78        80\n",
      "\n",
      "    accuracy                           0.83       223\n",
      "   macro avg       0.82      0.83      0.82       223\n",
      "weighted avg       0.84      0.83      0.84       223\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/1q/m8l_wvxd5dl8kccgv4xrsxtr0000gn/T/ipykernel_88131/318166747.py:2: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  X_train = X_train.to_dict(orient='record')\n",
      "/var/folders/1q/m8l_wvxd5dl8kccgv4xrsxtr0000gn/T/ipykernel_88131/318166747.py:3: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  X_test = X_test.to_dict(orient='record')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30957a78df82087ad0e293b0e2bba94c1e28de38d27414fc41b7300ce0c7e48e"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('p39': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}