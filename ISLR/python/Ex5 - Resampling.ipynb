{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Conceptual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true
   },
   "source": [
    "## 2. Bootstrap sample\n",
    "\n",
    "We will now derive the probability that a given observation is part of a bootstrap sample. Suppose that we obtain a bootstrap sample from a set of n observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### (a)-(c)\n",
    "\n",
    "(a) What is the probability that the first bootstrap observation is not the jth observation from the original sample? Justify your answer.\n",
    "\n",
    "(b) What is the probability that the second bootstrap observation is not the jth observation from the original sample?\n",
    "\n",
    "(c) Argue that the probability that the jth observation is not in the bootstrap sample is $(1 âˆ’ 1/n)^n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "(a) $1-1/n$\n",
    "\n",
    "(b) $1-1/n$\n",
    "\n",
    "(c) $(1-1/n)^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### (d)-(f)\n",
    "\n",
    "(d) When n = 5, what is the probability that the jth observation is in the bootstrap sample?\n",
    "\n",
    "(e) When n = 100, what is the probability that the jth observation is in the bootstrap sample?\n",
    "\n",
    "(f) When n = 10, 000, what is the probability that the jth observa- tion is in the bootstrap sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6723199999999999"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-(1-1/5)**5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6339676587267709"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-(1-1/100)**100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6321389535670295"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-(1-1/10000)**10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'probability')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prob_j_in_sample(n):\n",
    "    return 1 - (1 - 1/n)**n\n",
    "\n",
    "x = np.arange(1, 100000)\n",
    "y = np.array([prob_j_in_sample(n) for n in x])\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### (h) \n",
    "\n",
    "We will now investigate numerically the probability that a bootstrap sample of size n = 100 contains the jth observation. Here j = 4. We repeatedly create bootstrap samples, and each time we record whether or not the fourth observation is contained in the bootstrap sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6325632563256326"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "store = []\n",
    "\n",
    "for i in np.arange(1, 10000):\n",
    "    j_4 = np.sum((np.random.randint(1, 101, size=100) == 4))\n",
    "    store.append(j_4>0)\n",
    "\n",
    "np.mean(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true
   },
   "source": [
    "## 5. Logistic regression\n",
    "\n",
    "In Chapter 4, we used logistic regression to predict the probability of default using income and balance on the Default data set. We will now estimate the test error of this logistic regression model using the validation set approach. Do not forget to set a random seed before beginning your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>default_Yes</th>\n",
       "      <th>student_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       balance        income  default_Yes  student_Yes\n",
       "0   729.526495  44361.625074          0.0          0.0\n",
       "1   817.180407  12106.134700          0.0          1.0\n",
       "2  1073.549164  31767.138947          0.0          0.0\n",
       "3   529.250605  35704.493935          0.0          0.0\n",
       "4   785.655883  38463.495879          0.0          0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_df = pd.read_csv('./data/Default.csv', index_col='Unnamed: 0')\n",
    "default_df = default_df.reset_index().drop('index', axis=1)\n",
    "\n",
    "assert default_df.isna().sum().sum() == 0\n",
    "\n",
    "default_df = pd.get_dummies(default_df, dtype=np.float64).drop(['default_No', 'student_No'], axis=1)\n",
    "\n",
    "default_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true
   },
   "source": [
    "### (a) Fit\n",
    "\n",
    "Fit a logistic regression model that uses income and balance to predict default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078948\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>default_Yes</td>   <th>  No. Observations:  </th>   <td> 10000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  9997</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sat, 29 Feb 2020</td> <th>  Pseudo R-squ.:     </th>   <td>0.4594</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>18:21:10</td>     <th>  Log-Likelihood:    </th>  <td> -789.48</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -1460.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>4.541e-292</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  -11.5405</td> <td>    0.435</td> <td>  -26.544</td> <td> 0.000</td> <td>  -12.393</td> <td>  -10.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>    <td> 2.081e-05</td> <td> 4.99e-06</td> <td>    4.174</td> <td> 0.000</td> <td>  1.1e-05</td> <td> 3.06e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balance</th>   <td>    0.0056</td> <td>    0.000</td> <td>   24.835</td> <td> 0.000</td> <td>    0.005</td> <td>    0.006</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.14 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:            default_Yes   No. Observations:                10000\n",
       "Model:                          Logit   Df Residuals:                     9997\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Sat, 29 Feb 2020   Pseudo R-squ.:                  0.4594\n",
       "Time:                        18:21:10   Log-Likelihood:                -789.48\n",
       "converged:                       True   LL-Null:                       -1460.3\n",
       "Covariance Type:            nonrobust   LLR p-value:                4.541e-292\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    -11.5405      0.435    -26.544      0.000     -12.393     -10.688\n",
       "income      2.081e-05   4.99e-06      4.174      0.000     1.1e-05    3.06e-05\n",
       "balance        0.0056      0.000     24.835      0.000       0.005       0.006\n",
       "==============================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.14 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = 'default_Yes ~ income + balance'\n",
    "\n",
    "logit_fit = smf.logit(f, default_df).fit()\n",
    "logit_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "predictors = ['income', 'balance']\n",
    "\n",
    "X = default_df[predictors]\n",
    "y = default_df['default_Yes']\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "model = log_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.08091984e-05, 5.64710797e-03]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### (b) Estimate the test error\n",
    "\n",
    "Using the validation set approach, estimate the test error of this model. In order to do this, you must perform the following steps:\n",
    "\n",
    "\n",
    "i. Split the sample set into a training set and a validation set.\n",
    "\n",
    "ii. Fit a multiple logistic regression model using only the training observations.\n",
    "\n",
    "iii. Obtain a prediction of default status for each individual in the validation set by computing the posterior probability of default for that individual, and classifying the individual to the default category if the posterior probability is greater than 0.5.\n",
    "\n",
    "iv. Compute the validation set error, which is the fraction of the observations in the validation set that are misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def classify(clf, data, coef=True, auc=False, roc_curve=False, conf_mat=False, conf_labels=['Down', 'Up']):\n",
    "    X_train, X_test, y_train, y_test = data[0], data[1], data[2], data[3]\n",
    "\n",
    "    model = clf.fit(X_train, y_train)\n",
    "    if coef:\n",
    "        print('parameters: {}'.format(clf.coef_))\n",
    "    \n",
    "    acc = clf.score(X_test, y_test)\n",
    "    print('accuracy: {}'.format(acc))\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    print('precision: {}'.format(precision))\n",
    "    \n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    print('recall: {}'.format(recall))\n",
    "    \n",
    "    mat = confusion_matrix(y_test, y_pred)\n",
    "    print('confusion matrix \\n{}'.format(mat))\n",
    "    \n",
    "    print('total error rate: {:.1%}'.format(1 - np.trace(mat) / np.sum(mat)))\n",
    "    \n",
    "    if auc:\n",
    "        y_score = model.decision_function(X_test)\n",
    "        auc = roc_auc_score(y_test, y_score)\n",
    "        print('auc: {}'.format(auc))\n",
    "    \n",
    "    if roc_curve:\n",
    "        plot_roc_curve(clf, X_test, y_test)\n",
    "    \n",
    "    if conf_mat:\n",
    "        plot_confusion_matrix(clf, X_test, y_test, cmap=plt.cm.Blues, \n",
    "                              display_labels=conf_labels)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: [[1.57956908e-05 5.56457746e-03]]\n",
      "accuracy: 0.971\n",
      "precision: 0.8059701492537313\n",
      "recall: 0.2903225806451613\n",
      "confusion matrix \n",
      "[[4801   13]\n",
      " [ 132   54]]\n",
      "total error rate: 2.9%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = ['income', 'balance']\n",
    "\n",
    "X = default_df[predictors]\n",
    "y = default_df['default_Yes']\n",
    "\n",
    "data = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "classify(log_clf, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### (c) Different splits\n",
    "\n",
    "Repeat the process in (b) three times, using three different splits of the observations into a training set and a validation set. Comment on the results obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### (d) \n",
    "\n",
    "Now consider a logistic regression model that predicts the probability of default using income, balance, and a dummy variable for student. Estimate the test error for this model using the validation set approach. Comment on whether or not including a dummy variable for student leads to a reduction in the test error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: [[-1.38355453e-04  4.04131793e-03 -3.84660550e+00]]\n",
      "accuracy: 0.9644\n",
      "precision: 0.5769230769230769\n",
      "recall: 0.16129032258064516\n",
      "confusion matrix \n",
      "[[4792   22]\n",
      " [ 156   30]]\n",
      "total error rate: 3.6%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = ['income', 'balance', 'student_Yes']\n",
    "\n",
    "X = default_df[predictors]\n",
    "y = default_df['default_Yes']\n",
    "\n",
    "data = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "classify(log_clf, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 6. \n",
    "\n",
    "We continue to consider the use of a logistic regression model to predict the probability of default using income and balance on the Default data set. In particular, we will now compute estimates for the standard errors of the income and balance logistic regression coefficients in two different ways: \n",
    "\n",
    "(1) using the bootstrap, and (2) using the standard formula for computing the standard errors in the glm() function. Do not forget to set a random seed before beginning your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### (a) \n",
    "\n",
    "Using the summary() and glm() functions, determine the estimated standard errors for the coefficients associated with income and balance in a multiple logistic regression model that uses both predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "PatsyError",
     "evalue": "model is missing required outcome variables",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPatsyError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-f1006056032a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel_logit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_logit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Scoop\\apps\\miniconda3\\current\\envs\\kaggle\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36mfrom_formula\u001b[1;34m(cls, formula, data, subset, drop_cols, *args, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         tmp = handle_formula_data(data, None, formula, depth=eval_env,\n\u001b[1;32m--> 169\u001b[1;33m                                   missing=missing)\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesign_info\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mmax_endog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_formula_max_endog\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Scoop\\apps\\miniconda3\\current\\envs\\kaggle\\lib\\site-packages\\statsmodels\\formula\\formulatools.py\u001b[0m in \u001b[0;36mhandle_formula_data\u001b[1;34m(Y, X, formula, depth, missing)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             result = dmatrices(formula, Y, depth, return_type='dataframe',\n\u001b[1;32m---> 68\u001b[1;33m                                NA_action=na_action)\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;31m# if missing == 'raise' there's not missing_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Scoop\\apps\\miniconda3\\current\\envs\\kaggle\\lib\\site-packages\\patsy\\highlevel.py\u001b[0m in \u001b[0;36mdmatrices\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    310\u001b[0m                                       NA_action, return_type)\n\u001b[0;32m    311\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlhs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mPatsyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model is missing required outcome variables\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPatsyError\u001b[0m: model is missing required outcome variables"
     ]
    }
   ],
   "source": [
    "response   = 'default_Yes'\n",
    "predictors = ['income', 'balance']\n",
    "\n",
    "X_all = sm.add_constant(np.array(default_df[predictors]))\n",
    "y_all = np.array(default_df[response])\n",
    "\n",
    "model_logit = smf.logit(y_all, X_all).fit(disp=False) \n",
    "\n",
    "print(model_logit.summary())\n",
    "\n",
    "statsmodels_est = pd.DataFrame({'coef_sm': model_logit.params, 'SE_sm': model_logit.bse})\n",
    "statsmodels_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### (b) boot.fn()\n",
    "\n",
    "Write a function, boot.fn(), that takes as input the Default data set as well as an index of the observations, and that outputs the coefficient estimates for income and balance in the multiple logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def boot_fn(df, idx):\n",
    "    response   = 'default_Yes'\n",
    "    predictors = ['income', 'balance']\n",
    "    \n",
    "    X = sm.add_constant(np.array(df[predictors].loc[idx]))\n",
    "    y = np.array(df[response].loc[idx]) \n",
    "\n",
    "    model_logit = smf.Logit(y, X).fit(disp=False)\n",
    "    return model_logit.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### (c) boot()\n",
    "\n",
    "Use the boot() function together with your boot.fn() function to estimate the standard errors of the logistic regression coefficients for income and balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### (d) \n",
    "\n",
    "Comment on the estimated standard errors obtained using the glm() function and using your bootstrap function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
